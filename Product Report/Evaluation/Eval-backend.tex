\section{Backend}

The following section describes how the NetInf NRS application was evaluated and tested. 

\subsection{Video streaming protocol evaluation}
One of the problems discussed was reducing congestion when broadcasting content. This was solved by implementing an alternative way of sending chunked data as seen in Section \ref{sec:Chunked data streaming} according to the video streaming draft in Appendix \ref{VideoDraft}. In the following section this implementation is referred as the \textit{modified streaming}. 
The following test was conducted:

\begin{itemize}
\item Testing the modified version of NetInf video streaming. 
\item Testing the pure version of NetInf video streaming.
\item Comparison between both implementations of the NetInf Video streaming
\end{itemize}

The testing was done by transferring 500 chunks of bogus data between a number of different NetInf nodes running ERNI. All the receiving nodes started the transfer at the same time. To be able to publish N number of chunks in an easy and fast manner, the \textit{nn\_evaluation} module was implemented.


%The backbone of the entire application, this is the main product which the client requested. It is important to explore how much better this implementation of NetInf performs compared to location centric services today. 

\subsection{Pure video streaming evaluation setup}
The nodes that were included in the pure version of the streaming were the following:
Central NRS node, one stream source node that published all 500 NDOs to itself with \textit{fullput} set to True, then also published the NDO to the central NRS with \textit{fullput} false. The central NRS can not have the octets because otherwise it would provide all clients with the octects directly, hence prevent the network load to be more balanced.

Five clients nodes then got each chunk by:
\begin{enumerate}
\item search NRS for the chunk with chunk number and stream name.
\item get the NDO metadata and locators from the NRS.
\item fetch NDO with octects from one of the locators.
\item publish the NDO to itself 
\item add itself as a locator and publish to the NRS.
\item repeat the procedure for the next chunk.
\end{enumerate}

\subsection{Modified video streaming evaluation setup}
In this setup one node served as both the source and central NRS while there were five client nodes. The source first published the stream NDO to itself, then use the content dispatcher to put all the chunks in the storage.
The clients then get the stream NDO, added themselves as locator and published it to the NRS. To retrieve the chunks each client need to:
\begin{enumerate}
\item append the current chunk number to the NDO name.
\item send the request to one of the locators.
\item if status of the response is 404, repeat step 2.
\item store the octects in its storage.
\item increase the chunk number
\end{enumerate}

\subsection{Stream results and comparison} 
The Figure~\ref{fig:eval-stream-modvspure} shows that the pure NetInf streaming is faster when it comes to transferring all the chunks. This result is not that unexpected since the modified version have a lot of overhead in this case, if it tries to get chunks from another client which does not have them yet, this will yield in an 404 response and the client will need to try another source. While the pure NetInf will get a hit every time. 
 
Comparing CPU usage in Figure~\ref{fig:eval-stream-pure-cpu} and Figure~\ref{fig:eval-stream-mod-cpu}, it shows that even with only five receiving nodes the central NRS running with the pure version is struggling with handling the requests while the CPU load of the modified version is almost not noticeable.

\begin{figure}[h!]
	\centering
		\includegraphics[width=0.75\textwidth]{./img/eval-stream-plot-modvspure.png}
    	\caption{Pure streaming vs modified streaming}
	\label{fig:eval-stream-modvspure}
\end{figure}

\begin{figure}[h!]
	\centering
		\includegraphics[width=0.75\textwidth]{./img/eval-stream-pure-cpu.png}
    	\caption{Central NRS CPU usage during pure streaming}
	\label{fig:eval-stream-pure-cpu}
\end{figure}

\begin{figure}[h!]
	\centering
		\includegraphics[width=0.75\textwidth]{./img/eval-stream-mod-cpu.png}
    	\caption{Central NRS CPU usage during modified streaming}
	\label{fig:eval-stream-mod-cpu}
\end{figure}


\subsection{Notes on Interoperability}

There already are existing implementations created by SAIL and Ericsson Research for the NetInf protocol. In the beginning of the product life-cycle the client requested the development team to evaluate the interoperability of this product and the others, however as the product evolved the client requested that the interoperability be left to them to evaluate and that this development team continue with evaluating the video streaming instead.

Therefore the development team did not evaluate interoperability, but there is confidence that with minor tweaking of the code (due to differences in the various draft versions of the NetInf protocol spec) this product and others will become interoperable.

The following list describes the evaluation performed for testing the NetInf NRS application.

\begin{itemize}
\item Evaluation of the search time and get time for the supported databases
\item Measuring the number of requests per the frontend phone client
\end{itemize}
