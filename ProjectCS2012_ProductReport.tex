\documentclass[11pt]{report}
%Gummi|061|=)
\title{Project CS 2012 Product Report\\Uppsala University\\}

\author{Daniele Bacarella\\
		Jon Borglund\\
		Kiril Goguev\\
		Faroogh Hassan\\
		Marcus Ihlar\\
		Alexander Lindholm\\
		Knut Lorenzen\\
		Thomas Nordstr\"om\\
}

\date{}
\begin{document}

\maketitle

\tableofcontents

\chapter{Introduction}
\chapter{Information Centric Networking}

\subsection{Network of Information}
\subsection{Problems  today}
\section{Development Languages}
\subsection{Java-Android}
\subsection{Erlang}
The backend group decided with the client to have our product written in Erlang because of it's fault-tolerance, scalability and ease of distribution. Erlang is also a product of research done by the client in the past. This means that we have access to many individuals who are competent in the language at our disposal.
Erlang uses the idea of modules and nodes as a primary platform for serving a function, this allows our product to be broken up into several parts.
 
\subsection{Javascript}

Javascript was used when the backend group decided to create a simple http interface to the NetInf Name Resolution server in order to show a proof of concept (NetInf streaming). Javascript was used to calculate the hash of files for streaming.

\chapter{Product Description}
\section {Frontend - Android Client}
\section {Backend}

The client agreed on having an Erlang version of a NetInf Name Resolution Server(NetInf NRS).  Our backend product implements the current draft NetInf Protocol in a distributed and purely functional language. The product promises a high level of scalability and fault-tolerance. The client initially asked for only the NRS as a product however the backend team was able to complete the initial product in a timely manner, allowing for applications of this network technology to be explored. 


\subsection {Erlang NetInf Name Resolution Server}
The first of the two deliverables from the backend team to the client. The Erlang NetInf Name Resolution Server(NetInf NRS) provides a new way to organize and retrieve data on the internet. Based on a inital NetInf NRS protocol draft from development teams such as SAIL and Ericsson Research. This product allows for flexibility and extension of the existing protocol.

Erlang's concept of modularization allowed the team to break up the NRS functionality into distinctive convergence layers, real-time database switching, and even allow for a proof of concept video streaming client/protocol. 

\subsection{NetInf Video Streaming client/protocol}

The final of the deliverables from the backend team. The client asked for a proof of concept of a streaming protocol and client which lies on top of the Erlang NetInf NRS technology. The streaming protocol is a completely new addition to the NetInf draft. Our team came up with a way to utilize the code and transporting mechanism of the first product in order to stream video content, along with the protocol outlined below we have been able to create a http interface 'client' which allows you to see the streaming protocol in action as well access the NRS functionality. This particular product was not specified in the initial conversations with the client in September, but added late in the development cycle and is not meant to be a complete product.


\chapter{System Architecture}

\section {Android Client}

\section {NetInf NRS}

\subsection {Convergence Layers}

The NetInf NRS protocol introduces the concept of Convergence Layers(CL). CL's are specific protocols we can use to talk to other nodes on the network. For example we can use HyperTextTransferProtocol(HTTP), Erlang Messaging, User Datagram Protocol(UDP). We have implemented CL's as a set of Erlang modules whose sole jobs are to receive and send messages of the specific type of the CL, these set of modules  receive( CL handlers) clean/format(CL message handler/message specific formatter) and forward into and out of the system. This marks the first and last point of entry into our system and our first line of fault-tolerance. 

\subsubsection{HTTP}

The NetInf protocol draft discusses using HTTP as a primary layer of communication between nodes. All requests are detailed as coming in through HTTP messages and then subsequently changed into internal system NetInf Messages. The HTTP CL consists of three(3) modules. 

\begin{enumerate}
\item nn\_http\_handler - uses Erlang cowboy to receive and send requests HTTP requests to/from our system
\item nn\_message\_handler - Specifically spawned with the attached HTTP formatter in order to process requests
\item nn\_http\_formatting - Handles converting requests/responses from HTTP  to NetInf Messages and vice versa.
\end{enumerate}


\subsubsection{UDP}

The protocol draft lists it as a CL, however it's function is more like a discovery protocol for other NRS's of any type of implementation. The UDP CL we have currently broadcasts NetInf Messages on the network on a multicast IP 225.4.5.6 and port 2345. 

The UDP CL is supposed be called when a NetInf NRS 

Currently UDP GET and UDP SEARCH requests are supported. The framework for UDP PUBLISH requests are included in the current code base, but we have not specifically used it for the purpose of forwarding publishes. 


\subsection {Plug N' Play Database Wrappers}

The Erlang NetInf NRS includes functionality to allow for real-time database switching as well as providing an easy way to add interfaces to existing databases. Currently we have only added support for Riak, as well implementing a default Erlang list 'database'.  We designed the interface to be very intuitive to implement.

\subsection {Setup of Module}

All modules which wish to implement a database connection will use the custom nn\_database behaviour.

\begin {verbatim}
    -module(nn_database).
\end{verbatim}

The following functions must be implemented by your database wrapper

\textbf{Initialization}

\begin {verbatim}
    init() -> 
    	{ok, pid()} | {ok, registered_name:atom()} | {error, string()}
\end{verbatim}

The above function returns the connection for the specified database
Remember the init should return an identifier to the persistent process of the specified database.

\begin {verbatim}
    publish(NetInfObject::nn_proto:proto()) -> 
    	{ok, ReturnNetInfObj::nn_proto:proto()} | {ok, no_match}
\end{verbatim}

Takes the NetInfObject and returns: {ok,NewObject} where NewObject is the NDO that was published

\textbf{Get}

\begin {verbatim}
    get(Name::string()) -> 
    	{ok, nn_proto:proto()} | {ok, no_match}
\end{verbatim}

Takes the NetInf Name of the object and returns: {ok, Data} where Data is the NDO that was found or no\_match if not found.

\textbf{Unpublish}

\begin {verbatim}
    unpublish(NetInfObject::nn_proto:proto()) -> 
    	{ok, ReturnNetInfObj::nn_proto:proto()} | {ok, no_match}
\end{verbatim}

Takes the NetInfObject and returns {ok, ReturnNetInfObj} where ReturnNetInfObj is the NDO entry that was deleted from the specified database.

\textbf{Search}

\begin {verbatim}
    search(SearchList::list()) -> 
    	{ok, list()} | {ok, no_match}
\end{verbatim}

Takes a Erlang list of search keywords and returns a list of the NDO's which match those key words.
References

Please see the module src/nn\_database\_list as an example of the wrapper implementation for use with a 'list' database in the repository.



\section {NetInf Video Streaming Protocol}

\subsection{Introduction}

The purpose of this draft is to outline a design and protocol specification for enabling of streaming and chunking data within the current and existing netinf architecture.

\subsubsection{Proposed method of retrieving chunked NDOs}

The stream source will PUBLISH an NDO containing the filename as content. The object is marked as streaming video in the meta data. It also contains a locator to the stream source.

In order to access the stream, a receiver will first perform a NetInf-GET on the above filename object in order to retrieve the locator. 

In the next step the client can get the chunks. By replacing the hash algorithm in the NDO-name with \_demo\_ and sending a NetInf-GET to the source, the stream provider will return the octets of the most recent chunk and the chunk number in the metadata. This implies that the regular hash validation has been disabled.

For further chunks, the receiver will increment the chunk number and append it to the locator.\\

\textbf{Publish}\\
\begin{verbatim}
 ni:///sha-256;WkOCMB2aEQHrARjTldfhRE5OgZkZmCHzokcoVMnfp2Y

Get latest chunk
 ni:///demo;WkOCMB2aEQHrARjTldfhRE5OgZkZmCHzokcoVMnfp2Y

Get first chunk, append a 0 to the end of the hash
 ni:///demo;WkOCMB2aEQHrARjTldfhRE5OgZkZmCHzokcoVMnfp2Y0

Get the 32th chunk, append 32 to the end of the hash
 ni:///demo;WkOCMB2aEQHrARjTldfhRE5OgZkZmCHzokcoVMnfp2Y32
\end{verbatim}
 
If the receiver also acts as a cache, it will send a PUBLISH with the filename object and a locator pointing to itself to the NRS.
\\

\textbf{sequence\_diagram\_streaming.png}

\subsubsection{Testing criteria} 

For a simple test setup, in addition to our NetInf node, we need a receiving and a publishing client. A more sophisticated test could involve multiple receivers, to demonstrate the caching.

A use case we can use for testing is one where our source of the content is a pre-encoded video file of a particular size.

In the example below we will assume a video file of 700 megabytes.

A client (Publisher) will have a default chunk size which we will use to chunk up the source file. For example we will use 1 megabyte chunk size.

We can calculate from the Publisher that we will have 700 chunks, of 1 megabyte each numbered 0-699. 

A second client (receiver) knowing the name of the video file will then perform a GET request within the NetInf node (to keep things simple, we assume it knows the object's name already).

The client will now start generating consecutive GET's with the sequence numbers constantly increasing and expect to receive the appropriate chunk.

Also poll the NRS for new locators, to reduce the load of the network.

Until the GET's generate a 404 because the unique sequence number has increased past a chunk number that is not published.

\subsubsection{Extra notes}

Chunk size is going to be a configurable option in the publishing client.

The polling logic needs to be implemented in the client, that is how often the receiver should get a new chunk or check if a new chunk exists.  

\chapter{Evaluation and testing}
\chapter{Related work}
\chapter{Future Work}
\chapter{Conclusion}
\chapter{Installation Instructions}
\section {Frontend}
\subsection {Dependencies}
\section {Backend}
\subsection {Dependencies}
\end{document}
